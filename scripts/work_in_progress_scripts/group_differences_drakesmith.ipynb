{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook to calculate group differences based on paper drakesmith et al\n",
    "\n",
    "This is the  multi-threshold permutation correction approach and consists:\n",
    "\n",
    "1) Apply thresholds to networks and compute network metrics for all networks across all thresholds\n",
    "2) Compute test statistics for each network\n",
    "3) Permute across groups to get the null distrubition\n",
    "4) Take the maximum test statistic across all thresholds for each permutation resulting in one summarised null statistic for each permutation. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scona as scn\n",
    "import matplotlib.pyplot as plt\n",
    "import functions.plotting_functions as Pfun\n",
    "import functions.statistical_functions as Sfun\n",
    "import seaborn as sns\n",
    "sns.set_style('dark')\n",
    "from decouple import config\n",
    "\n",
    "data = config('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    }
   ],
   "source": [
    "lh_volume = pd.read_csv(f'{data}/lh_volume.dat',sep='\\t').drop(['BrainSegVolNotVent', 'eTIV'],axis=1).rename(columns={'lh.aparc.volume':'G-Number'})\n",
    "rh_volume =  pd.read_csv(f'{data}/rh_volume.dat',sep='\\t').drop(['BrainSegVolNotVent', 'eTIV','rh.aparc.volume'],axis=1)\n",
    "\n",
    "group = pd.read_csv(f'{data}/cortical_measures.csv').iloc[0:,2]\n",
    "\n",
    "volume = pd.concat([lh_volume, rh_volume, group],axis=1)\n",
    "\n",
    "names = list(volume.columns.drop(['G-Number','age_adjusted_group']))\n",
    "\n",
    "centroids = pd.read_csv(f'{data}/atlas.csv')\n",
    "centroids = centroids[['x.mni', 'y.mni', 'z.mni']].to_numpy()\n",
    "\n",
    "\n",
    "group = volume.groupby('age_adjusted_group')\n",
    "aan = group.get_group('AAN').reset_index(drop=True)\n",
    "hc = group.get_group('HC').reset_index(drop=True)\n",
    "wr = group.get_group('WR').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Apply thresholds to networks and compute network metrics for all networks across all thresholds\n",
    "\n",
    "First the threshold range needs to be decided. To do this the methodology used is taken from Bassett et al (https://doi.org/10.1073/pnas.0606005103) where the upper limit must not exceed 2 * natural log(nodes). \n",
    "Starting point of 4 is used otherwise minimum spanning tree is too large and throws up error message.\n",
    "\n",
    "Threshold values are stored in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_value=[]\n",
    "for threshold in range(4 , 100):\n",
    "    aan_graphs = Sfun.create_graphs(aan.iloc[:,1:69], names, centroids, threshold=threshold)\n",
    "    aan_graphs['graph_threshold'].calculate_nodal_measures()\n",
    "    cal = aan_graphs['graph_threshold'].report_nodal_measures()\n",
    "    \n",
    "    if cal['degree'].mean() > 2 * np.log(len(aan_graphs['graph_threshold'].nodes())):\n",
    "        break\n",
    "    \n",
    "    threshold_value.append(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create graphs at the pre-defined thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\n",
    "    'aan_graphs':[],\n",
    "    'hc_graphs':[],\n",
    "    'wr_graphs':[]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in threshold_value:\n",
    "    aan_graphs = Sfun.create_graphs(aan.iloc[:,1:69], names, centroids, threshold=threshold)\n",
    "    aan_graphs['graph_threshold'].__name__ = f'aan_graph_threshold_value_{threshold}'\n",
    "    result['aan_graphs'].append(aan_graphs['graph_threshold'])\n",
    "\n",
    "    hc_graphs = Sfun.create_graphs(hc.iloc[:,1:69], names, centroids, threshold=threshold)\n",
    "    hc_graphs['graph_threshold'].__name__ = f'hc_graph_threshold_value_{threshold}'\n",
    "    result['hc_graphs'].append(hc_graphs['graph_threshold'])\n",
    "\n",
    "    wr_graphs = Sfun.create_graphs(wr.iloc[:,1:69], names, centroids, threshold=threshold)\n",
    "    wr_graphs['graph_threshold'].__name__ = f'wr_graph_threshold_value_{threshold}'\n",
    "    result['wr_graphs'].append(wr_graphs['graph_threshold'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally calculate global measures for each graph at the threshold ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for keys, values in result.items():\n",
    "    for graph_object in values:\n",
    "        global_measures = graph_object.calculate_global_measures()\n",
    "        measures[f'{graph_object.__name__}'] = []\n",
    "        measures[f'{graph_object.__name__}'].append(global_measures)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Compute test statistics for each network\n",
    "\n",
    "Calculate the test statistic for each condition. This is going to be the difference between each global measure for two groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_statistics = {\n",
    "    'aan_hc':{},\n",
    "    'wr_hc':{},\n",
    "    'wr_aan':{}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in threshold_value:\n",
    "    for keys, value in measures['aan_graph_threshold_value_4'][0].items():\n",
    "        statistic_aan_hc =  measures[f'aan_graph_threshold_value_{threshold}'][0][keys] - measures[f'hc_graph_threshold_value_{threshold}'][0][keys]\n",
    "        statistic_wr_hc =  measures[f'wr_graph_threshold_value_{threshold}'][0][keys] - measures[f'hc_graph_threshold_value_{threshold}'][0][keys]\n",
    "        statistic_wr_aan =  measures[f'wr_graph_threshold_value_{threshold}'][0][keys] - measures[f'aan_graph_threshold_value_{threshold}'][0][keys]\n",
    "        \n",
    "        key = f'{keys}_at_threshold_value_{threshold}'\n",
    "      \n",
    "        test_statistics['aan_hc'][key] = statistic_aan_hc \n",
    "        test_statistics['wr_hc'][key] = statistic_wr_hc\n",
    "        test_statistics['wr_aan'][key] = statistic_wr_aan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Permute across groups to get the null distrubition\n",
    "\n",
    "Now we permutate to create a null distrubtion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permuations(permutations:int, length_of_group_1:int, length_of_group_2:int, participants:pd.DataFrame, names:list, centroids:np.float64, threshold:int) -> dict:\n",
    "    measures = ['average_clustering', 'average_shortest_path_length', 'assortativity', 'modularity', 'efficiency']\n",
    "    null_distribution ={\n",
    "        \n",
    "        'average_clustering':[],\n",
    "        'average_shortest_path_length':[], \n",
    "        'assortativity':[], \n",
    "        'modularity':[], \n",
    "        'efficiency':[]\n",
    "    \n",
    "    }\n",
    "    \n",
    "    for perm in range(permutations):\n",
    "        group_1_participants = participants.sample(n=length_of_group_1)\n",
    "        group_2_participants = participants.sample(n=length_of_group_2)\n",
    "        \n",
    "        group_1_graphs = Sfun.create_graphs(group_1_participants.iloc[:,1:69], names, centroids, threshold=threshold)\n",
    "        group_2_graphs = Sfun.create_graphs(group_2_participants.iloc[:,1:69], names, centroids)\n",
    "        \n",
    "        group_1_values = group_1_graphs['graph_threshold'].calculate_global_measures()\n",
    "        group_2_graphs = group_2_graphs['graph_threshold'].calculate_global_measures()\n",
    "    \n",
    "        for meas in measures:\n",
    "            crit_val = group_1_values[meas] -  group_2_graphs[meas]\n",
    "            null_distribution[meas].append(crit_val)\n",
    "            \n",
    "    return null_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_hc_df = pd.concat([aan, hc], ignore_index=True)\n",
    "aan_wr_df = pd.concat([aan, wr], ignore_index=True)\n",
    "wr_hc_df = pd.concat([wr, hc], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_distribution = {\n",
    "    'aan_hc':{},\n",
    "    'wr_hc':{},\n",
    "    'wr_aan':{}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "for threshold in threshold_value:\n",
    "    aan_hc_perm = permuations(10, len(aan['G-Number']), len(hc['G-Number']), aan_hc_df, names, centroids, threshold)\n",
    "    aan_wr_perm = permuations(10, len(aan['G-Number']), len(wr['G-Number']), aan_wr_df, names, centroids, threshold)\n",
    "    wr_hc_perm = permuations(10, len(wr['G-Number']), len(hc['G-Number']), wr_hc_df, names, centroids, threshold)\n",
    "    \n",
    "    key = f'thresholded_value_{threshold}'\n",
    "    null_distribution['aan_hc'][key] = aan_hc_perm \n",
    "    null_distribution['wr_hc'][key] = aan_wr_perm\n",
    "    null_distribution['wr_aan'][key] = wr_hc_perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2734855136084287\n",
      "-0.08077260755048243\n"
     ]
    }
   ],
   "source": [
    "print(max(null_distribution['aan_hc']['thresholded_value_4']['average_shortest_path_length']))\n",
    "print(test_statistics['aan_hc']['average_shortest_path_length_at_threshold_value_4'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Take the maximum test statistic across all thresholds for each permutation resulting in one summarised null statistic for each permutation. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_max_null_stat(null_distribution:dict, group_key:str, measure_key:str, list_number:int) -> int:\n",
    "    \n",
    "    '''\n",
    "    Function to loop through each element in a list for each thresold value.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    null_distribution:dict dictionary of null_distribution\n",
    "    group_key:str dictionary key for group \n",
    "    measure_key:str dictionary key for the graph theory measure.\n",
    "    list_number:int list index of permutation\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    max_null_statistic:int max null statistic for that permutation.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    values = []\n",
    "    for threshold in threshold_value:\n",
    "        values.append(null_distribution[group_key][f'thresholded_value_{threshold}'][measure_key][list_number])\n",
    "    \n",
    "    max_null_statistic = max(values, key=abs)\n",
    "    return max_null_statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_stat_summarized = {\n",
    "    \n",
    "    'aan_hc':{},\n",
    "    'wr_hc':{},\n",
    "    'wr_aan':{}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO need to get max_null_stat for each permutation into dictionary\n",
    "#for perm in range(0, 10):\n",
    "#    find_max_null_stat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('scn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d6aaeafbb34bd8ccb4b94759bad6d8a43f22b1f97d06ebd89ca25d302d210f79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
