{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Permutation of group differences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import scona as scn\n",
    "from scona.visualisations import plot_network_measures, plot_degree_dist, plot_rich_club\n",
    "import matplotlib.pyplot as plt\n",
    "import nilearn.plotting as plot\n",
    "import functions.plotting_functions as Pfun\n",
    "import functions.statistical_functions as Sfun\n",
    "import seaborn as sns\n",
    "sns.set_style('dark')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code creates the enviornmental variable for where the data is stored. Create a .env file in the directory with the file path to data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decouple import config\n",
    "\n",
    "data = config('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>G-Number</th>\n",
       "      <th>lh_bankssts_volume</th>\n",
       "      <th>lh_caudalanteriorcingulate_volume</th>\n",
       "      <th>lh_caudalmiddlefrontal_volume</th>\n",
       "      <th>lh_cuneus_volume</th>\n",
       "      <th>lh_entorhinal_volume</th>\n",
       "      <th>lh_fusiform_volume</th>\n",
       "      <th>lh_inferiorparietal_volume</th>\n",
       "      <th>lh_inferiortemporal_volume</th>\n",
       "      <th>lh_isthmuscingulate_volume</th>\n",
       "      <th>...</th>\n",
       "      <th>rh_rostralmiddlefrontal_volume</th>\n",
       "      <th>rh_superiorfrontal_volume</th>\n",
       "      <th>rh_superiorparietal_volume</th>\n",
       "      <th>rh_superiortemporal_volume</th>\n",
       "      <th>rh_supramarginal_volume</th>\n",
       "      <th>rh_frontalpole_volume</th>\n",
       "      <th>rh_temporalpole_volume</th>\n",
       "      <th>rh_transversetemporal_volume</th>\n",
       "      <th>rh_insula_volume</th>\n",
       "      <th>age_adjusted_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-G2001</td>\n",
       "      <td>2885.0</td>\n",
       "      <td>1875.0</td>\n",
       "      <td>5887.0</td>\n",
       "      <td>2985.0</td>\n",
       "      <td>2195.0</td>\n",
       "      <td>8822.0</td>\n",
       "      <td>12823.0</td>\n",
       "      <td>10927.0</td>\n",
       "      <td>2617.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15777.0</td>\n",
       "      <td>21509.0</td>\n",
       "      <td>13309.0</td>\n",
       "      <td>11317.0</td>\n",
       "      <td>9869.0</td>\n",
       "      <td>1616.0</td>\n",
       "      <td>3326.0</td>\n",
       "      <td>999.0</td>\n",
       "      <td>6634.0</td>\n",
       "      <td>AAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-G2002</td>\n",
       "      <td>3685.0</td>\n",
       "      <td>1842.0</td>\n",
       "      <td>7653.0</td>\n",
       "      <td>4092.0</td>\n",
       "      <td>2116.0</td>\n",
       "      <td>11551.0</td>\n",
       "      <td>13769.0</td>\n",
       "      <td>13400.0</td>\n",
       "      <td>2909.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20591.0</td>\n",
       "      <td>23157.0</td>\n",
       "      <td>14659.0</td>\n",
       "      <td>14117.0</td>\n",
       "      <td>8507.0</td>\n",
       "      <td>1640.0</td>\n",
       "      <td>2310.0</td>\n",
       "      <td>1084.0</td>\n",
       "      <td>7527.0</td>\n",
       "      <td>AAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-G2003</td>\n",
       "      <td>3865.0</td>\n",
       "      <td>2396.0</td>\n",
       "      <td>6341.0</td>\n",
       "      <td>2826.0</td>\n",
       "      <td>2120.0</td>\n",
       "      <td>11673.0</td>\n",
       "      <td>13934.0</td>\n",
       "      <td>12608.0</td>\n",
       "      <td>2553.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17216.0</td>\n",
       "      <td>23072.0</td>\n",
       "      <td>13261.0</td>\n",
       "      <td>12634.0</td>\n",
       "      <td>10292.0</td>\n",
       "      <td>1457.0</td>\n",
       "      <td>2316.0</td>\n",
       "      <td>875.0</td>\n",
       "      <td>7393.0</td>\n",
       "      <td>AAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-G2004</td>\n",
       "      <td>2621.0</td>\n",
       "      <td>2329.0</td>\n",
       "      <td>6160.0</td>\n",
       "      <td>2971.0</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>9591.0</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>11468.0</td>\n",
       "      <td>2395.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14858.0</td>\n",
       "      <td>19432.0</td>\n",
       "      <td>13154.0</td>\n",
       "      <td>11849.0</td>\n",
       "      <td>9458.0</td>\n",
       "      <td>1216.0</td>\n",
       "      <td>2477.0</td>\n",
       "      <td>854.0</td>\n",
       "      <td>7986.0</td>\n",
       "      <td>AAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-G2005</td>\n",
       "      <td>2276.0</td>\n",
       "      <td>1949.0</td>\n",
       "      <td>7127.0</td>\n",
       "      <td>3406.0</td>\n",
       "      <td>2480.0</td>\n",
       "      <td>10771.0</td>\n",
       "      <td>9233.0</td>\n",
       "      <td>12424.0</td>\n",
       "      <td>2463.0</td>\n",
       "      <td>...</td>\n",
       "      <td>14933.0</td>\n",
       "      <td>19112.0</td>\n",
       "      <td>10911.0</td>\n",
       "      <td>10574.0</td>\n",
       "      <td>8782.0</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>2971.0</td>\n",
       "      <td>842.0</td>\n",
       "      <td>6432.0</td>\n",
       "      <td>AAN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    G-Number  lh_bankssts_volume  lh_caudalanteriorcingulate_volume  \\\n",
       "0  sub-G2001              2885.0                             1875.0   \n",
       "1  sub-G2002              3685.0                             1842.0   \n",
       "2  sub-G2003              3865.0                             2396.0   \n",
       "3  sub-G2004              2621.0                             2329.0   \n",
       "4  sub-G2005              2276.0                             1949.0   \n",
       "\n",
       "   lh_caudalmiddlefrontal_volume  lh_cuneus_volume  lh_entorhinal_volume  \\\n",
       "0                         5887.0            2985.0                2195.0   \n",
       "1                         7653.0            4092.0                2116.0   \n",
       "2                         6341.0            2826.0                2120.0   \n",
       "3                         6160.0            2971.0                2017.0   \n",
       "4                         7127.0            3406.0                2480.0   \n",
       "\n",
       "   lh_fusiform_volume  lh_inferiorparietal_volume  lh_inferiortemporal_volume  \\\n",
       "0              8822.0                     12823.0                     10927.0   \n",
       "1             11551.0                     13769.0                     13400.0   \n",
       "2             11673.0                     13934.0                     12608.0   \n",
       "3              9591.0                     13000.0                     11468.0   \n",
       "4             10771.0                      9233.0                     12424.0   \n",
       "\n",
       "   lh_isthmuscingulate_volume  ...  rh_rostralmiddlefrontal_volume  \\\n",
       "0                      2617.0  ...                         15777.0   \n",
       "1                      2909.0  ...                         20591.0   \n",
       "2                      2553.0  ...                         17216.0   \n",
       "3                      2395.0  ...                         14858.0   \n",
       "4                      2463.0  ...                         14933.0   \n",
       "\n",
       "   rh_superiorfrontal_volume  rh_superiorparietal_volume  \\\n",
       "0                    21509.0                     13309.0   \n",
       "1                    23157.0                     14659.0   \n",
       "2                    23072.0                     13261.0   \n",
       "3                    19432.0                     13154.0   \n",
       "4                    19112.0                     10911.0   \n",
       "\n",
       "   rh_superiortemporal_volume  rh_supramarginal_volume  rh_frontalpole_volume  \\\n",
       "0                     11317.0                   9869.0                 1616.0   \n",
       "1                     14117.0                   8507.0                 1640.0   \n",
       "2                     12634.0                  10292.0                 1457.0   \n",
       "3                     11849.0                   9458.0                 1216.0   \n",
       "4                     10574.0                   8782.0                 1606.0   \n",
       "\n",
       "   rh_temporalpole_volume  rh_transversetemporal_volume  rh_insula_volume  \\\n",
       "0                  3326.0                         999.0            6634.0   \n",
       "1                  2310.0                        1084.0            7527.0   \n",
       "2                  2316.0                         875.0            7393.0   \n",
       "3                  2477.0                         854.0            7986.0   \n",
       "4                  2971.0                         842.0            6432.0   \n",
       "\n",
       "   age_adjusted_group  \n",
       "0                 AAN  \n",
       "1                 AAN  \n",
       "2                 AAN  \n",
       "3                 AAN  \n",
       "4                 AAN  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lh_volume = pd.read_csv(f'{data}/lh_volume.dat',sep='\\t').drop([\n",
    "                     'BrainSegVolNotVent', 'eTIV'],axis=1).rename(columns={'lh.aparc.volume':'G-Number'})\n",
    "\n",
    "rh_volume =  pd.read_csv(f'{data}/rh_volume.dat',sep='\\t').drop([\n",
    "                       'BrainSegVolNotVent', 'eTIV','rh.aparc.volume'],axis=1)\n",
    "\n",
    "group = pd.read_csv(f'{data}/cortical_measures.csv').iloc[0:,2]\n",
    "\n",
    "volume = pd.concat([lh_volume, rh_volume, group],axis=1)\n",
    "\n",
    "names = list(volume.columns.drop(['G-Number','age_adjusted_group']))\n",
    "\n",
    "centroids = pd.read_csv(f'{data}/atlas.csv')\n",
    "\n",
    "centroids = centroids[['x.mni', 'y.mni', 'z.mni']].to_numpy()\n",
    "\n",
    "group = volume.groupby('age_adjusted_group')\n",
    "aan = group.get_group('AAN').reset_index(drop=True)\n",
    "hc = group.get_group('HC').reset_index(drop=True)\n",
    "wr = group.get_group('WR').reset_index(drop=True)\n",
    "aan.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_residuals_df = scn.create_residuals_df(aan.iloc[:,1:69], names)\n",
    "aan_corr_matrix = scn.create_corrmat(aan_residuals_df, method='pearson')\n",
    "aan_graph = scn.BrainNetwork(network=aan_corr_matrix, parcellation=names, centroids=centroids)\n",
    "aan_graph_threshold = aan_graph.threshold(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr_residuals_df = scn.create_residuals_df(wr.iloc[:,1:69], names)\n",
    "wr_corr_matrix = scn.create_corrmat(wr_residuals_df, method='pearson')\n",
    "wr_graph = scn.BrainNetwork(network=wr_corr_matrix, parcellation=names, centroids=centroids)\n",
    "wr_graph_threshold = wr_graph.threshold(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_residuals_df = scn.create_residuals_df(hc.iloc[:,1:69], names)\n",
    "hc_corr_matrix = scn.create_corrmat(hc_residuals_df, method='pearson')\n",
    "hc_graph = scn.BrainNetwork(network=hc_corr_matrix, parcellation=names, centroids=centroids)\n",
    "hc_graph_threshold = hc_graph.threshold(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_bundle_aan = scn.GraphBundle([aan_graph_threshold], ['AAN_graph_thresholded'])\n",
    "brain_bundle_aan.create_random_graphs('AAN_graph_thresholded', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_bundle_wr = scn.GraphBundle([wr_graph_threshold], ['WR_graph_thresholded'])\n",
    "brain_bundle_wr.create_random_graphs('WR_graph_thresholded', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_bundle_hc = scn.GraphBundle([aan_graph_threshold], ['HC_graph_thresholded'])\n",
    "brain_bundle_hc.create_random_graphs('HC_graph_thresholded', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aan_global_measures = brain_bundle_aan.report_global_measures() \n",
    "aan_global_measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_global_measures = brain_bundle_hc.report_global_measures() \n",
    "hc_global_measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr_global_measures = brain_bundle_wr.report_global_measures() \n",
    "wr_global_measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pfun.distro_plots(aan_global_measures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = ['average_clustering', 'average_shortest_path_length', 'assortativity', 'modularity', 'efficiency'] \n",
    "measure = measures[1]\n",
    "tcrit_value = aan_global_measures[measure].mean() - hc_global_measures[measure].mean() #- wr_global_measures[measure].mean()\n",
    "\n",
    "\n",
    "permutations = 10000\n",
    "\n",
    "combined = np.concatenate([aan_global_measures[measure].values, hc_global_measures[measure].values]) #wr_global_measures[measure].values, \n",
    "\n",
    "index_1 = len(aan_global_measures[measure].values)\n",
    "#index_2 = len(wr_global_measures[measure].values) + len(wr_global_measures[measure].values)\n",
    "\n",
    "ctvalue=[]\n",
    "for perm in range(permutations):\n",
    "        np.random.shuffle(combined)\n",
    "        random_group_one = combined[0: index_1]\n",
    "        #random_group_two = combined[index_1: index_2]\n",
    "        random_group_three = combined[index_1:]\n",
    "        crit_val = random_group_one.mean() - random_group_three.mean() #- random_group_two.mean() \n",
    "        ctvalue.append(crit_val)\n",
    "\n",
    "array = np.array(ctvalue)\n",
    "mean = array.mean()\n",
    "std_dev = np.std(ctvalue)\n",
    "lower_2std = mean - 2*std_dev\n",
    "upper_2std =  mean + 2*std_dev\n",
    "lower_1std = mean - std_dev\n",
    "upper_1std = mean + std_dev\n",
    "\n",
    "if tcrit_value >= mean:\n",
    "        sum = [val for val in ctvalue if val >= tcrit_value]\n",
    "        print('upper')\n",
    "else:\n",
    "        sum = [val for val in ctvalue if val <= tcrit_value]\n",
    "        print('lower')\n",
    "     \n",
    "     #if tcrit_value > 0 and mean > 0:\n",
    "     #           sum = [val for val in ctvalue if abs(val) <= abs(tcrit_value)]\n",
    "     #           print('lower 1')\n",
    "     #else:\n",
    "     #           sum = [val for val in ctvalue if abs(val) >= abs(tcrit_value)]\n",
    "     #           print('lower 2')\n",
    "\n",
    "        \n",
    "        \n",
    "pval = len(sum) / permutations\n",
    "\n",
    "\n",
    "\n",
    "print(pval)\n",
    "\n",
    "print(tcrit_value)\n",
    "print([lower_2std, upper_2std])\n",
    "hist = sns.displot(data=ctvalue, height=10).set(title=f'Histplot for {measure} after {permutations} permuatations')\n",
    "hist.refline(x=tcrit_value, color='purple')\n",
    "hist.refline(x=lower_2std, linestyle='-', color='black')\n",
    "hist.refline(x=upper_2std, linestyle='-', color='black')\n",
    "hist.refline(x=lower_1std, linestyle='-', color='red')\n",
    "hist.refline(x=upper_1std, linestyle='-', color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = ['average_clustering', 'average_shortest_path_length', 'assortativity', 'modularity', 'efficiency'] \n",
    "measure = measures[4]\n",
    "\n",
    "tcrit_value = aan_global_measures[measure].mean() - wr_global_measures[measure].mean() - hc_global_measures[measure].mean() \n",
    "\n",
    "permutations = 10000\n",
    "\n",
    "combined = np.concatenate([aan_global_measures[measure].values, wr_global_measures[measure].values, hc_global_measures[measure].values]) \n",
    "\n",
    "index_1 = len(aan_global_measures[measure].values)\n",
    "index_2 = len(wr_global_measures[measure].values) + len(wr_global_measures[measure].values)\n",
    "\n",
    "ctvalue=[]\n",
    "\n",
    "for perm in range(permutations):\n",
    "        np.random.shuffle(combined)\n",
    "        random_group_one = combined[0: index_1]\n",
    "        random_group_two = combined[index_1: index_2]\n",
    "        random_group_three = combined[index_1:]\n",
    "        crit_val = random_group_one.mean() - random_group_two.mean() - random_group_three.mean()  \n",
    "        ctvalue.append(crit_val)\n",
    "\n",
    "mean_val = Sfun.mean_std(ctvalue)\n",
    "\n",
    "\n",
    "if tcrit_value >= mean_val['mean']:\n",
    "        sum = [val for val in ctvalue if val >= tcrit_value]\n",
    "        print('upper')\n",
    "else:\n",
    "        sum = [val for val in ctvalue if val <= tcrit_value]\n",
    "        print('lower')\n",
    "     \n",
    "     #if tcrit_value > 0 and mean > 0:\n",
    "     #           sum = [val for val in ctvalue if abs(val) <= abs(tcrit_value)]\n",
    "     #           print('lower 1')\n",
    "     #else:\n",
    "     #           sum = [val for val in ctvalue if abs(val) >= abs(tcrit_value)]\n",
    "     #           print('lower 2')\n",
    "\n",
    "        \n",
    "        \n",
    "pval = len(sum) / permutations\n",
    "\n",
    "\n",
    "\n",
    "print(pval)\n",
    "\n",
    "print(abs(tcrit_value))\n",
    "print(abs(mean_val['mean']))\n",
    "Pfun.pval_plotting(ctvalue, tcrit_value, measure, permutations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pval_plotting(ctvalues, tcrit_value, measure, permutations):\n",
    "    \n",
    "    '''\n",
    "    Wrapper around seaborn displot.\n",
    "    Function to plot null distribution with 2 std either side and true critical value.\n",
    "\n",
    "    Parameters\n",
    "    -----------------------------------------------------------------\n",
    "    ctvalues : list, list of crticial values from the null distrubtion.\n",
    "    tcrit_value: int True crtical value of a test.\n",
    "    measure: str, name of the measure (used in title of the graph)\n",
    "    permutations: int, number of permuations (used in title of the graph)\n",
    "\n",
    "\n",
    "    Returns\n",
    "    -----------------------------------------------------------------\n",
    "    hist: histogram of null distribution with upper and lower std with\n",
    "          true value.\n",
    "    '''\n",
    "    \n",
    "    #Calculates the mean and std deviation of null distribution\n",
    "    array = np.array(ctvalue)\n",
    "    mean = array.mean()\n",
    "    std_dev = np.std(ctvalue)\n",
    "\n",
    "    lower_1std = mean - std_dev\n",
    "    upper_1std = mean + std_dev\n",
    "    lower_2std = mean - 2*std_dev\n",
    "    upper_2std =  mean + 2*std_dev\n",
    "    \n",
    "    #plots \n",
    "    hist = sns.displot(data=ctvalues, height=10).set(title=f'Histplot for {measure} after {permutations} permuatations')\n",
    "    hist.refline(x=tcrit_value, color='purple')\n",
    "    hist.refline(x=lower_2std, linestyle='-', color='black')\n",
    "    hist.refline(x=upper_2std, linestyle='-', color='black')\n",
    "    hist.refline(x=lower_1std, linestyle='-', color='red')\n",
    "    hist.refline(x=upper_1std, linestyle='-', color='red')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo(group_one, group_two, group_three, permutations, plotting=False, measure='None'):\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    Function to run a monte_carlo permuation hypothesis testing.\n",
    "    \n",
    "    Calculates a critical value then randomly shuffles groups calculating the crticial value \n",
    "    for each permutation.\n",
    "\n",
    "    Pval calculated as:\n",
    "    sum of all values greater than critical value / number of permutations\n",
    "\n",
    "    Parameters\n",
    "    ----------------------------------------------\n",
    "    group one: numpy array of values for group one\n",
    "    group one: numpy array of values for group two\n",
    "    group one: numpy array of values for group three\n",
    "    permutations: int, number of permutations to perform.\n",
    "\n",
    "    Returns\n",
    "    ---------------------------------------------\n",
    "    results: dict object with critical value, pvalue and std\n",
    "    \n",
    "    '''\n",
    "\n",
    "    critical_value = group_one.mean() - group_two.mean() - group_three.mean()\n",
    "    combined = np.concatenate([group_one, group_two, group_three])\n",
    "\n",
    "    index_1 = len(group_one)\n",
    "    index_2 = len(group_two) + len(group_two)\n",
    "\n",
    "    ctvalue = []\n",
    "\n",
    "    for perm in range(permutations):\n",
    "        np.random.shuffle(combined)\n",
    "        random_group_one = combined[0: index_1]\n",
    "        random_group_two = combined[index_1: index_2]\n",
    "        random_group_three = combined[index_2:]\n",
    "        crit_val = random_group_one.mean() - random_group_two.mean() - random_group_three.mean()\n",
    "        ctvalue.append(crit_val)\n",
    "    \n",
    "    array = np.array(ctvalue)\n",
    "    mean = array.mean()\n",
    "    std_dev = np.std(ctvalue)\n",
    "    lower_2std = mean - 2*std_dev\n",
    "    upper_2std =  mean + 2*std_dev\n",
    "\n",
    "    if tcrit_value >= mean:\n",
    "            sum = [val for val in ctvalue if val >= tcrit_value]\n",
    "\n",
    "    else:\n",
    "            sum = [val for val in ctvalue if val <= tcrit_value]\n",
    "             \n",
    "    pval = len(sum) / permutations\n",
    "\n",
    "\n",
    "\n",
    "print(pval)\n",
    "\n",
    "print(abs(tcrit_value))\n",
    "print(abs(mean))\n",
    "#print([lower_2std, upper_2std])\n",
    "hist = sns.displot(data=ctvalue, height=10).set(title=f'Histplot for {measure} after {permutations} permuatations')\n",
    "hist.refline(x=tcrit_value, color='purple')\n",
    "hist.refline(x=lower_2std, linestyle='-', color='black')\n",
    "hist.refline(x=upper_2std, linestyle='-', color='black')\n",
    "plt.show()\n",
    "\n",
    "    result = {'critval':critical_value, 'pval': pval,'lower_std':lower_2std, 'upper_std':upper_2std}\n",
    "\n",
    "    if plotting == True:\n",
    "        pval_plotting(ctvalue, critical_value, measure, permutations)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure = 'assortativity' \n",
    "plots_for_pval = monte_carlo(aan_global_measures[measure].values, wr_global_measures[measure].values, hc_global_measures[measure].values, permutations=50000, plotting=True, measure=measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for measure in aan_global_measures.columns: \n",
    "    eff = monte_carlo(aan_global_measures[measure].values, wr_global_measures[measure].values, hc_global_measures[measure].values, permutations=50000)\n",
    "    print(eff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_2(group_one, group_two, permutations):\n",
    "    \n",
    "    '''\n",
    "    Function to run a monte_carlo permuation hypothesis testing.\n",
    "    \n",
    "    Calculates a critical value then randomly shuffles groups calculating the crticial value \n",
    "    for each permutation.\n",
    "\n",
    "    Pval calculated as:\n",
    "    sum of all values greater than critical value / number of permutations\n",
    "\n",
    "    Parameters\n",
    "    ----------------------------------------------\n",
    "    group one: numpy array of values for group one\n",
    "    group one: numpy array of values for group two\n",
    "    group one: numpy array of values for group three\n",
    "    permutations: int, number of permutations to perform.\n",
    "\n",
    "    Returns\n",
    "    ---------------------------------------------\n",
    "    results: dict object with critical value and pvalue\n",
    "    \n",
    "    '''\n",
    "\n",
    "    critical_value = group_one.mean() - group_two.mean()\n",
    "    combined = np.concatenate([group_one, group_two])\n",
    "\n",
    "    ctvalue = []\n",
    "\n",
    "    index_1 = len(group_one)\n",
    "\n",
    "    for perm in range(permutations):\n",
    "        np.random.shuffle(combined)\n",
    "        random_group_one = combined[:index_1]\n",
    "        random_group_two = combined[index_1:]\n",
    "        crit_val = random_group_one.mean() - random_group_two.mean() \n",
    "        ctvalue.append(crit_val)\n",
    "    \n",
    "    sum = [val for val in ctvalue if abs(val) >= abs(critical_value)]\n",
    "    \n",
    "    #print(len(sum))\n",
    "    #print('\\n', ctvalue,'\\n')\n",
    "\n",
    "    pval = len(sum) / permutations\n",
    "\n",
    "    result = {'critval':critical_value, 'pval': pval}\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for measure in aan_global_measures.columns: \n",
    "    eff = monte_carlo_2(aan_global_measures[measure].values, hc_global_measures[measure].values, permutations=50000)\n",
    "    print(f'Group difference between AAN and HC for {measure}','pval=', eff['pval'],'critical value:',eff['critval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for measure in aan_global_measures.columns: \n",
    "    eff = monte_carlo_2(aan_global_measures[measure].values, wr_global_measures[measure].values, permutations=50000)\n",
    "    print(f'Group difference between AAN and WR for {measure}','pval=', eff['pval'],'critical value:',eff['critval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for measure in aan_global_measures.columns: \n",
    "    eff = monte_carlo_2(hc_global_measures[measure].values, wr_global_measures[measure].values, permutations=50000)\n",
    "    print(f'Group difference between HC and WR for {measure}','pval=', eff['pval'],'critical value:',eff['critval'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d6aaeafbb34bd8ccb4b94759bad6d8a43f22b1f97d06ebd89ca25d302d210f79"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('scn': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
